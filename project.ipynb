{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, SimpleRNN, Reshape, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From openCV documentation\n",
    "\n",
    "def preprocess_image(img_path, bbox): ## bbox is bounding box dimensions provided in the words.txt labels file \n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) ##read in grayscale since works well for our database as the images are in grayscale anyway\n",
    "    if img is None: # handling images that may be hard to read\n",
    "        print(f\"Failed to load image: {img_path}\")\n",
    "        return None\n",
    "    height, width = img.shape\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    if img.size == 0:\n",
    "        print(f\"Empty cropped image for bbox {bbox} in image: {img_path}\")\n",
    "        return None\n",
    "    thresh_val, bin_img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) #thresh_binary specifies binary threshold.\n",
    "    resized_image = cv2.resize(bin_img, (128, 32)) ## resizing image to normalize\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: words/a01/a01-117/a01-117-05-02.png\n",
      "Failed to load image: words/r06/r06-022/r06-022-03-05.png\n",
      "# of images not loaded due to bad data:  18864\n"
     ]
    }
   ],
   "source": [
    "def load_labels_and_images(word_txt_path, img_folder_path):\n",
    "    labels = []\n",
    "    images = []\n",
    "    \n",
    "    with open(word_txt_path, 'r') as file:\n",
    "        lines = file.readlines() ## reading txt file that has the labels\n",
    "    bad_load_count = 0\n",
    "    for line in lines:\n",
    "        if line.startswith('#') or not line.strip(): #based on format of txt file \n",
    "            continue\n",
    "        parts = line.strip().split()\n",
    "        if parts[1]!='ok':\n",
    "            bad_load_count+=1\n",
    "            continue\n",
    "        word_id = parts[0]\n",
    "        bbox = list(map(int, parts[3:7]))\n",
    "        label = parts[-1]\n",
    "        \n",
    "        subfolder = word_id.split('-')[0] #traversing through folder\n",
    "        img_folder = os.path.join(img_folder_path, subfolder, (word_id.split('-')[0]+'-'+word_id.split('-')[1]))\n",
    "        img_name = f\"{word_id}.png\"\n",
    "        img_path = os.path.join(img_folder, img_name)\n",
    "        \n",
    "        img = preprocess_image(img_path, bbox)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    print(\"# of images not loaded due to bad data: \", bad_load_count)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_labels_and_images('words.txt', 'words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96454, 12214)\n"
     ]
    }
   ],
   "source": [
    "## Prep data for NNs\n",
    "X = np.array(images).astype('float32')/255.0 #normalizing pixel values\n",
    "X = np.expand_dims(X, axis=-1) #adding channel dimension (indicating color) to img array\n",
    "y = pd.factorize(labels)[0] \n",
    "y = to_categorical(y) \n",
    "\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 50ms/step - accuracy: 0.2260 - loss: 5.9819 - val_accuracy: 0.3615 - val_loss: 4.9131\n",
      "Epoch 2/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 45ms/step - accuracy: 0.4000 - loss: 4.1570 - val_accuracy: 0.4184 - val_loss: 4.8971\n",
      "Epoch 3/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 45ms/step - accuracy: 0.4595 - loss: 3.4353 - val_accuracy: 0.4360 - val_loss: 5.0650\n",
      "Epoch 4/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 42ms/step - accuracy: 0.5066 - loss: 2.9063 - val_accuracy: 0.4446 - val_loss: 5.3792\n",
      "Epoch 5/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 44ms/step - accuracy: 0.5581 - loss: 2.4507 - val_accuracy: 0.4341 - val_loss: 6.0483\n",
      "Epoch 6/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 48ms/step - accuracy: 0.6001 - loss: 2.0876 - val_accuracy: 0.4480 - val_loss: 6.7815\n",
      "Epoch 7/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.6460 - loss: 1.7913 - val_accuracy: 0.4473 - val_loss: 7.9333\n",
      "Epoch 8/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 44ms/step - accuracy: 0.6865 - loss: 1.5185 - val_accuracy: 0.4339 - val_loss: 8.2272\n",
      "Epoch 9/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.7191 - loss: 1.3191 - val_accuracy: 0.4330 - val_loss: 9.1083\n",
      "Epoch 10/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.7523 - loss: 1.1225 - val_accuracy: 0.4323 - val_loss: 10.5569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c4b1e110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([ #sequential model \n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape), \n",
    "        MaxPooling2D((2, 2)), \n",
    "        Conv2D(64, (3, 3), activation='relu'), \n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(), \n",
    "        Dense(128, activation='relu'), #Adds a fully connected layer with 128 neurons\n",
    "        Dense(num_classes, activation='softmax')  #Adds a fully connected layer with 128 neurons. Softmax to output probabilities\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (32, 128, 1)\n",
    "num_classes = y.shape[1] \n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "cnn_model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 21ms/step - accuracy: 0.0661 - loss: 7.0438 - val_accuracy: 0.1039 - val_loss: 6.7216\n",
      "Epoch 2/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 23ms/step - accuracy: 0.1054 - loss: 6.3312 - val_accuracy: 0.1067 - val_loss: 6.8774\n",
      "Epoch 3/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 20ms/step - accuracy: 0.1158 - loss: 6.1522 - val_accuracy: 0.1130 - val_loss: 6.9663\n",
      "Epoch 4/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 19ms/step - accuracy: 0.1174 - loss: 6.1217 - val_accuracy: 0.1240 - val_loss: 7.0452\n",
      "Epoch 5/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 20ms/step - accuracy: 0.1273 - loss: 6.0056 - val_accuracy: 0.1344 - val_loss: 7.2289\n",
      "Epoch 6/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - accuracy: 0.1416 - loss: 5.9209 - val_accuracy: 0.0690 - val_loss: 7.4858\n",
      "Epoch 7/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 19ms/step - accuracy: 0.0973 - loss: 6.6287 - val_accuracy: 0.1099 - val_loss: 7.4968\n",
      "Epoch 8/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - accuracy: 0.1200 - loss: 6.2479 - val_accuracy: 0.0712 - val_loss: 7.6570\n",
      "Epoch 9/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.0939 - loss: 6.2949 - val_accuracy: 0.1080 - val_loss: 7.4672\n",
      "Epoch 10/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 19ms/step - accuracy: 0.1089 - loss: 6.1715 - val_accuracy: 0.1183 - val_loss: 7.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c4bec940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_rnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        Reshape((32, 128), input_shape=input_shape), #reshape converts into format needed for RNN\n",
    "        SimpleRNN(128, return_sequences=True), \n",
    "        SimpleRNN(128),  \n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax') \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "rnn_model = create_rnn_model(input_shape, num_classes)\n",
    "\n",
    "rnn_model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3015/3015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - accuracy: 0.7870 - loss: 1.1362\n",
      "CNN Accuracy: 72.43038415908813%\n",
      "\u001b[1m3015/3015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.1220 - loss: 6.1132\n",
      "RNN Accuracy: 12.273208051919937%\n"
     ]
    }
   ],
   "source": [
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X, y)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy * 100}%\")\n",
    "\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X, y)\n",
    "print(f\"RNN Accuracy: {rnn_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 50ms/step - accuracy: 0.1550 - loss: 6.3673 - val_accuracy: 0.3191 - val_loss: 5.0510\n",
      "Epoch 2/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 54ms/step - accuracy: 0.3458 - loss: 4.3293 - val_accuracy: 0.3793 - val_loss: 4.6553\n",
      "Epoch 3/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 57ms/step - accuracy: 0.4153 - loss: 3.5608 - val_accuracy: 0.4072 - val_loss: 4.5847\n",
      "Epoch 4/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 60ms/step - accuracy: 0.4676 - loss: 3.0580 - val_accuracy: 0.4210 - val_loss: 4.6679\n",
      "Epoch 5/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 54ms/step - accuracy: 0.5069 - loss: 2.6753 - val_accuracy: 0.4437 - val_loss: 4.6519\n",
      "Epoch 6/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 56ms/step - accuracy: 0.5398 - loss: 2.3798 - val_accuracy: 0.4409 - val_loss: 4.7142\n",
      "Epoch 7/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 56ms/step - accuracy: 0.5728 - loss: 2.1156 - val_accuracy: 0.4480 - val_loss: 4.7269\n",
      "Epoch 8/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 55ms/step - accuracy: 0.6025 - loss: 1.8941 - val_accuracy: 0.4595 - val_loss: 4.7942\n",
      "Epoch 9/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 57ms/step - accuracy: 0.6299 - loss: 1.7006 - val_accuracy: 0.4583 - val_loss: 4.8720\n",
      "Epoch 10/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 57ms/step - accuracy: 0.6497 - loss: 1.5458 - val_accuracy: 0.4583 - val_loss: 4.8826\n",
      "\u001b[1m3015/3015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 15ms/step - accuracy: 0.6838 - loss: 1.3918\n",
      "Accuracy: 72.43038415908813%\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(32*128, activation='relu'), #flatten makes it 1-D layer, but we need a 2D layer of input shape to go into the reshape function.\n",
    "        Reshape((32, 128)),  ## reshaping for RNN layer\n",
    "        SimpleRNN(128, return_sequences=True),\n",
    "        SimpleRNN(128),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = (32, 128, 1)\n",
    "num_classes = y.shape[1]\n",
    "cnn_rnn_model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "\n",
    "cnn_rnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_rnn_model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_rnn_loss, cnn_rnn_accuracy = cnn_rnn_model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.6950900554657%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined Model 1 Accuracy: {cnn_rnn_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-RNN Combined Model with Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 62ms/step - accuracy: 0.1547 - loss: 6.3510 - val_accuracy: 0.3126 - val_loss: 5.0444\n",
      "Epoch 2/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 60ms/step - accuracy: 0.3189 - loss: 4.5124 - val_accuracy: 0.3671 - val_loss: 4.7837\n",
      "Epoch 3/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 78ms/step - accuracy: 0.3688 - loss: 3.9642 - val_accuracy: 0.3876 - val_loss: 4.6952\n",
      "Epoch 4/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 93ms/step - accuracy: 0.4052 - loss: 3.5734 - val_accuracy: 0.4106 - val_loss: 4.5984\n",
      "Epoch 5/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 94ms/step - accuracy: 0.4264 - loss: 3.3002 - val_accuracy: 0.4179 - val_loss: 4.7247\n",
      "Epoch 6/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 99ms/step - accuracy: 0.4524 - loss: 3.0681 - val_accuracy: 0.4220 - val_loss: 4.8077\n",
      "Epoch 7/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 96ms/step - accuracy: 0.4645 - loss: 2.9081 - val_accuracy: 0.4399 - val_loss: 4.6963\n",
      "Epoch 8/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 103ms/step - accuracy: 0.4762 - loss: 2.7907 - val_accuracy: 0.4374 - val_loss: 4.7812\n",
      "Epoch 9/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 102ms/step - accuracy: 0.4871 - loss: 2.6857 - val_accuracy: 0.4432 - val_loss: 4.7929\n",
      "Epoch 10/10\n",
      "\u001b[1m2412/2412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 110ms/step - accuracy: 0.4980 - loss: 2.5770 - val_accuracy: 0.4516 - val_loss: 4.7992\n",
      "\u001b[1m3015/3015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 32ms/step - accuracy: 0.5665 - loss: 2.0837\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model_with_dropout(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),  ## dropout is regularization technique to reduce overfitting; does so by randomly deactivating certain neurons\n",
    "        Dense(32*128, activation='relu'),\n",
    "        Reshape((32, 128)),\n",
    "        SimpleRNN(128, return_sequences=True),\n",
    "        Dropout(0.2),  ## dropout for RNN\n",
    "        SimpleRNN(128),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (32, 128, 1)\n",
    "num_classes = y.shape[1]\n",
    "cnn_rnn_model_dropout = create_cnn_rnn_model_with_dropout(input_shape, num_classes)\n",
    "\n",
    "cnn_rnn_model_dropout.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_rnn_model_dropout.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_rnn_dropout_loss, cnn_rnn_dropout_accuracy = cnn_rnn_model_dropout.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model 2 (with dropout) Accuracy: 55.0936222076416%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined Model 2 (with dropout) Accuracy: {cnn_rnn_dropout_accuracy * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
